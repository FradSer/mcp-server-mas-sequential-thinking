"""Six Thinking Hats Sequential Processor

å®ç°åŸºäº De Bono å…­å¸½æ€ç»´çš„é¡ºåºå¤„ç†å™¨ï¼Œé›†æˆåˆ° Agno Workflow ç³»ç»Ÿä¸­ã€‚
æ”¯æŒå•å¸½åˆ°å…­å¸½çš„æ™ºèƒ½åºåˆ—å¤„ç†ï¼Œè§£å†³"ç»¼åˆ+è¯„å®¡"åˆ†ç¦»é—®é¢˜ã€‚
"""

import logging
import time
from dataclasses import dataclass
from typing import Any

from agno.workflow.types import StepOutput

from .models import ThoughtData
from .modernized_config import get_model_config
from .six_hats_core import HatColor, HatComplexity, SixHatsAgentFactory
from .six_hats_router import RoutingDecision, SixHatsIntelligentRouter

logger = logging.getLogger(__name__)


@dataclass
class SixHatsProcessingResult:
    """å…­å¸½å¤„ç†ç»“æœ"""
    content: str
    strategy_used: str
    hat_sequence: list[str]
    processing_time: float
    complexity_score: float
    cost_reduction: float
    individual_results: dict[str, str]  # æ¯ä¸ªå¸½å­çš„ç»“æœ
    step_name: str


class SixHatsSequentialProcessor:
    """å…­å¸½é¡ºåºæ€ç»´å¤„ç†å™¨"""

    def __init__(self):
        self.model_config = get_model_config()
        self.hat_factory = SixHatsAgentFactory()
        self.router = SixHatsIntelligentRouter()

    async def process_thought_with_six_hats(
        self, thought_data: ThoughtData, context_prompt: str = ""
    ) -> SixHatsProcessingResult:
        """ä½¿ç”¨å…­å¸½æ€ç»´å¤„ç†æ€æƒ³"""
        start_time = time.time()

        logger.info("ğŸ© SIX HATS PROCESSING START:")
        logger.info(f"  ğŸ“ Input: {thought_data.thought[:100]}...")
        logger.info(f"  ğŸ“‹ Context: {len(context_prompt)} chars")

        try:
            # æ­¥éª¤1: æ™ºèƒ½è·¯ç”±å†³ç­–
            routing_decision = self.router.route_thought(thought_data)

            logger.info(f"  ğŸ¯ Strategy: {routing_decision.strategy.name}")
            logger.info(f"  ğŸ¨ Hat Sequence: {[hat.value for hat in routing_decision.strategy.hat_sequence]}")

            # æ­¥éª¤2: æ ¹æ®å¤æ‚åº¦æ‰§è¡Œç›¸åº”å¤„ç†
            if routing_decision.strategy.complexity == HatComplexity.SINGLE:
                result = await self._process_single_hat(
                    thought_data, context_prompt, routing_decision
                )
            elif routing_decision.strategy.complexity == HatComplexity.DOUBLE:
                result = await self._process_double_hat_sequence(
                    thought_data, context_prompt, routing_decision
                )
            elif routing_decision.strategy.complexity == HatComplexity.TRIPLE:
                result = await self._process_triple_hat_sequence(
                    thought_data, context_prompt, routing_decision
                )
            else:  # FULL
                result = await self._process_full_hat_sequence(
                    thought_data, context_prompt, routing_decision
                )

            processing_time = time.time() - start_time

            # åˆ›å»ºæœ€ç»ˆç»“æœ
            final_result = SixHatsProcessingResult(
                content=result["final_content"],
                strategy_used=routing_decision.strategy.name,
                hat_sequence=[hat.value for hat in routing_decision.strategy.hat_sequence],
                processing_time=processing_time,
                complexity_score=routing_decision.complexity_metrics.complexity_score,
                cost_reduction=routing_decision.estimated_cost_reduction,
                individual_results=result.get("individual_results", {}),
                step_name="six_hats_processing"
            )

            logger.info("âœ… SIX HATS PROCESSING COMPLETED:")
            logger.info(f"  â±ï¸  Time: {processing_time:.3f}s")
            logger.info(f"  ğŸ’° Cost Reduction: {routing_decision.estimated_cost_reduction:.1f}%")
            logger.info(f"  ğŸ“Š Output Length: {len(final_result.content)} chars")

            return final_result

        except Exception as e:
            processing_time = time.time() - start_time
            logger.error(f"âŒ Six Hats processing failed after {processing_time:.3f}s: {e}")

            return SixHatsProcessingResult(
                content=f"Six Hats processing failed: {e!s}",
                strategy_used="error_fallback",
                hat_sequence=[],
                processing_time=processing_time,
                complexity_score=0.0,
                cost_reduction=0.0,
                individual_results={},
                step_name="error_handling"
            )

    async def _process_single_hat(
        self, thought_data: ThoughtData, context: str, decision: RoutingDecision
    ) -> dict[str, Any]:
        """å¤„ç†å•å¸½æ¨¡å¼"""
        hat_color = decision.strategy.hat_sequence[0]
        logger.info(f"  ğŸ© SINGLE HAT MODE: {hat_color.value}")

        # åˆ›å»ºå•ä¸ªå¸½å­agent
        model = self.model_config.create_agent_model()
        agent = self.hat_factory.create_hat_agent(
            hat_color, model, context, {}
        )

        # æ‰§è¡Œå¤„ç†
        result = await agent.arun(input=thought_data.thought)

        # æå–å†…å®¹
        content = self._extract_content(result)

        return {
            "final_content": content,
            "individual_results": {hat_color.value: content}
        }

    async def _process_double_hat_sequence(
        self, thought_data: ThoughtData, context: str, decision: RoutingDecision
    ) -> dict[str, Any]:
        """å¤„ç†åŒå¸½åºåˆ—"""
        hat1, hat2 = decision.strategy.hat_sequence
        logger.info(f"  ğŸ© DOUBLE HAT SEQUENCE: {hat1.value} â†’ {hat2.value}")

        model = self.model_config.create_agent_model()
        individual_results = {}

        # ç¬¬ä¸€é¡¶å¸½å­
        agent1 = self.hat_factory.create_hat_agent(hat1, model, context, {})
        result1 = await agent1.arun(input=thought_data.thought)
        content1 = self._extract_content(result1)
        individual_results[hat1.value] = content1

        logger.info(f"    âœ… {hat1.value} hat completed")

        # ç¬¬äºŒé¡¶å¸½å­ï¼ˆåŸºäºç¬¬ä¸€é¡¶å¸½å­çš„ç»“æœï¼‰
        previous_results = {hat1.value: content1}
        agent2 = self.hat_factory.create_hat_agent(
            hat2, model, context, previous_results
        )

        # æ„å»ºç¬¬äºŒå¸½å­çš„è¾“å…¥
        hat2_input = f"""
Original thought: {thought_data.thought}

{hat1.value.title()} hat perspective: {content1}

Now apply {hat2.value} hat thinking to this.
"""

        result2 = await agent2.arun(input=hat2_input)
        content2 = self._extract_content(result2)
        individual_results[hat2.value] = content2

        logger.info(f"    âœ… {hat2.value} hat completed")

        # å¯¹äºåŒå¸½åºåˆ—ï¼Œç›´æ¥ç»„åˆç»“æœ
        final_content = self._combine_dual_hat_results(
            hat1, content1, hat2, content2, thought_data.thought
        )

        return {
            "final_content": final_content,
            "individual_results": individual_results
        }

    async def _process_triple_hat_sequence(
        self, thought_data: ThoughtData, context: str, decision: RoutingDecision
    ) -> dict[str, Any]:
        """å¤„ç†ä¸‰å¸½åºåˆ—ï¼ˆæ ¸å¿ƒæ¨¡å¼ï¼‰"""
        hat_sequence = decision.strategy.hat_sequence
        logger.info(f"  ğŸ© TRIPLE HAT SEQUENCE: {' â†’ '.join(hat.value for hat in hat_sequence)}")

        model = self.model_config.create_agent_model()
        individual_results = {}
        previous_results = {}

        # é¡ºåºæ‰§è¡Œä¸‰ä¸ªå¸½å­
        for i, hat_color in enumerate(hat_sequence):
            logger.info(f"    ğŸ© Processing {hat_color.value} hat ({i+1}/3)")

            agent = self.hat_factory.create_hat_agent(
                hat_color, model, context, previous_results
            )

            # æ„å»ºè¾“å…¥
            if i == 0:
                # ç¬¬ä¸€ä¸ªå¸½å­ï¼šåŸå§‹è¾“å…¥
                hat_input = thought_data.thought
            else:
                # åç»­å¸½å­ï¼šåŒ…å«ä¹‹å‰çš„ç»“æœ
                hat_input = self._build_sequential_input(
                    thought_data.thought, previous_results, hat_color
                )

            result = await agent.arun(input=hat_input)
            content = self._extract_content(result)
            individual_results[hat_color.value] = content
            previous_results[hat_color.value] = content

            logger.info(f"      âœ… {hat_color.value} hat completed")

        # å¦‚æœæœ€åä¸€ä¸ªæ˜¯è“å¸½ï¼Œå®ƒçš„ç»“æœå°±æ˜¯æœ€ç»ˆç»“æœ
        if hat_sequence[-1] == HatColor.BLUE:
            final_content = individual_results[HatColor.BLUE.value]
        else:
            # å¦åˆ™ï¼Œåˆ›å»ºç®€å•çš„ç»¼åˆ
            final_content = self._synthesize_triple_results(
                individual_results, hat_sequence, thought_data.thought
            )

        return {
            "final_content": final_content,
            "individual_results": individual_results
        }

    async def _process_full_hat_sequence(
        self, thought_data: ThoughtData, context: str, decision: RoutingDecision
    ) -> dict[str, Any]:
        """å¤„ç†å®Œæ•´å…­å¸½åºåˆ—"""
        hat_sequence = decision.strategy.hat_sequence
        logger.info(f"  ğŸ© FULL HAT SEQUENCE: {' â†’ '.join(hat.value for hat in hat_sequence)}")

        model = self.model_config.create_agent_model()
        individual_results = {}
        previous_results = {}

        # é¡ºåºæ‰§è¡Œæ‰€æœ‰å¸½å­
        for i, hat_color in enumerate(hat_sequence):
            logger.info(f"    ğŸ© Processing {hat_color.value} hat ({i+1}/{len(hat_sequence)})")

            agent = self.hat_factory.create_hat_agent(
                hat_color, model, context, previous_results
            )

            # æ„å»ºè¾“å…¥
            if i == 0 or hat_color == HatColor.BLUE:
                # ç¬¬ä¸€ä¸ªå¸½å­å’Œè“å¸½ï¼šç‰¹æ®Šå¤„ç†
                if hat_color == HatColor.BLUE and i > 0:
                    # è“å¸½æ•´åˆæ‰€æœ‰å‰é¢çš„ç»“æœ
                    hat_input = self._build_blue_hat_integration_input(
                        thought_data.thought, previous_results
                    )
                else:
                    hat_input = thought_data.thought
            else:
                # å…¶ä»–å¸½å­ï¼šé¡ºåºå¤„ç†
                hat_input = self._build_sequential_input(
                    thought_data.thought, previous_results, hat_color
                )

            result = await agent.arun(input=hat_input)
            content = self._extract_content(result)
            individual_results[hat_color.value] = content
            previous_results[hat_color.value] = content

            logger.info(f"      âœ… {hat_color.value} hat completed")

        # æœ€ç»ˆè“å¸½çš„ç»“æœå°±æ˜¯æœ€ç»ˆç»“æœ
        final_blue_result = None
        for hat_color in reversed(hat_sequence):
            if hat_color == HatColor.BLUE:
                final_blue_result = individual_results[hat_color.value]
                break

        final_content = final_blue_result or self._synthesize_full_results(
            individual_results, hat_sequence, thought_data.thought
        )

        return {
            "final_content": final_content,
            "individual_results": individual_results
        }

    def _extract_content(self, result: Any) -> str:
        """æå–agentè¿è¡Œç»“æœçš„å†…å®¹"""
        if hasattr(result, "content"):
            content = result.content
            if isinstance(content, str):
                return content.strip()
            return str(content).strip()
        if isinstance(result, str):
            return result.strip()
        return str(result).strip()

    def _build_sequential_input(
        self, original_thought: str, previous_results: dict[str, str], current_hat: HatColor
    ) -> str:
        """æ„å»ºé¡ºåºå¤„ç†çš„è¾“å…¥"""
        input_parts = [f"Original thought: {original_thought}", ""]

        if previous_results:
            input_parts.append("Previous hat perspectives:")
            for hat_name, content in previous_results.items():
                input_parts.append(f"  {hat_name.title()} hat: {content[:200]}{'...' if len(content) > 200 else ''}")
            input_parts.append("")

        input_parts.append(f"Now apply {current_hat.value} hat thinking to this situation.")

        return "\n".join(input_parts)

    def _build_blue_hat_integration_input(
        self, original_thought: str, all_results: dict[str, str]
    ) -> str:
        """æ„å»ºè“å¸½æ•´åˆè¾“å…¥"""
        input_parts = [
            f"Original thought: {original_thought}",
            "",
            "All hat perspectives to integrate:",
        ]

        for hat_name, content in all_results.items():
            if hat_name != "blue":  # é¿å…åŒ…å«ä¹‹å‰çš„è“å¸½ç»“æœ
                input_parts.append(f"  {hat_name.title()} hat: {content}")

        input_parts.extend([
            "",
            "As the Blue Hat (metacognitive orchestrator), provide a unified, comprehensive integration of all perspectives.",
            "This should be the FINAL, COMPLETE response that users will see.",
            "Do not separate synthesis and critique - provide one coherent answer."
        ])

        return "\n".join(input_parts)

    def _combine_dual_hat_results(
        self, hat1: HatColor, content1: str, hat2: HatColor, content2: str, original_thought: str
    ) -> str:
        """ç»„åˆåŒå¸½ç»“æœ"""
        return f"""Based on the thought: "{original_thought}"

{hat1.value.title()} Hat Perspective:
{content1}

{hat2.value.title()} Hat Perspective:
{content2}

Integrated Understanding:
These two perspectives complement each other - the {hat1.value} hat provides {self._get_hat_contribution(hat1)}, while the {hat2.value} hat offers {self._get_hat_contribution(hat2)}. Together, they give us a balanced view that considers both aspects important for this situation."""

    def _synthesize_triple_results(
        self, results: dict[str, str], hat_sequence: list[HatColor], original_thought: str
    ) -> str:
        """ç»¼åˆä¸‰å¸½ç»“æœ"""
        synthesis_parts = [f'Thinking about: "{original_thought}"', ""]

        for hat_color in hat_sequence:
            hat_name = hat_color.value
            content = results.get(hat_name, "")
            if content:
                synthesis_parts.append(f"{hat_name.title()} Hat: {content}")
                synthesis_parts.append("")

        synthesis_parts.append("Integrated Conclusion:")
        synthesis_parts.append(f"This analysis using {len(hat_sequence)} thinking perspectives reveals a multi-faceted understanding. Each hat contributes its unique viewpoint, creating a comprehensive approach to the question.")

        return "\n".join(synthesis_parts)

    def _synthesize_full_results(
        self, results: dict[str, str], hat_sequence: list[HatColor], original_thought: str
    ) -> str:
        """ç»¼åˆå®Œæ•´å…­å¸½ç»“æœ"""
        # å¦‚æœæœ‰è“å¸½ç»“æœï¼Œä¼˜å…ˆä½¿ç”¨
        blue_result = results.get("blue")
        if blue_result:
            return blue_result

        # å¦åˆ™åˆ›å»ºç»¼åˆ
        return self._synthesize_triple_results(results, hat_sequence, original_thought)

    def _get_hat_contribution(self, hat_color: HatColor) -> str:
        """è·å–å¸½å­çš„è´¡çŒ®æè¿°"""
        contributions = {
            HatColor.WHITE: "factual information and objective data",
            HatColor.RED: "emotional insights and intuitive responses",
            HatColor.BLACK: "critical analysis and risk assessment",
            HatColor.YELLOW: "positive possibilities and value identification",
            HatColor.GREEN: "creative alternatives and innovative solutions",
            HatColor.BLUE: "process management and integrated thinking"
        }
        return contributions.get(hat_color, "specialized thinking")


# åˆ›å»ºå…¨å±€å¤„ç†å™¨å®ä¾‹
_six_hats_processor = SixHatsSequentialProcessor()


# ä¾¿åˆ©å‡½æ•°
async def process_with_six_hats(thought_data: ThoughtData, context: str = "") -> SixHatsProcessingResult:
    """ä½¿ç”¨å…­å¸½æ€ç»´å¤„ç†æ€æƒ³çš„ä¾¿åˆ©å‡½æ•°"""
    return await _six_hats_processor.process_thought_with_six_hats(thought_data, context)


def create_six_hats_step_output(result: SixHatsProcessingResult) -> StepOutput:
    """å°†å…­å¸½å¤„ç†ç»“æœè½¬æ¢ä¸º Agno StepOutput"""
    return StepOutput(
        content=result.content,
        success=True,
        step_name=result.step_name,
    )
